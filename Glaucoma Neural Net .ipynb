{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 118) (101,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('patients_data_from_images.csv')\n",
    "df['label'] = (df['total_md_gap_per_year']<-2).astype(int)\n",
    "\n",
    "X = df.drop(['total_md_gap_per_year', 'label'], axis = 1)\n",
    "Y = df['label']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = X.fillna(0)\n",
    "X = scaler.fit_transform(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FullBN (5) -- meta/aux input at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, kernel_initializer=\"glorot_normal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 118)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                7616      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,465\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 20 samples, validate on 81 samples\n",
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s - loss: 0.5618 - acc: 0.7500 - val_loss: 0.9282 - val_acc: 0.0988\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s - loss: 0.4716 - acc: 0.8500 - val_loss: 0.9225 - val_acc: 0.0988\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s - loss: 0.4190 - acc: 0.9500 - val_loss: 0.9137 - val_acc: 0.0988\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s - loss: 0.3970 - acc: 0.9500 - val_loss: 0.9027 - val_acc: 0.0988\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s - loss: 0.3829 - acc: 0.9500 - val_loss: 0.8912 - val_acc: 0.0988\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s - loss: 0.3700 - acc: 0.9500 - val_loss: 0.8809 - val_acc: 0.0988\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s - loss: 0.3580 - acc: 1.0000 - val_loss: 0.8722 - val_acc: 0.0988\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s - loss: 0.3489 - acc: 1.0000 - val_loss: 0.8660 - val_acc: 0.0988\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s - loss: 0.3405 - acc: 1.0000 - val_loss: 0.8612 - val_acc: 0.1235\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s - loss: 0.3320 - acc: 1.0000 - val_loss: 0.8577 - val_acc: 0.1235\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s - loss: 0.3238 - acc: 1.0000 - val_loss: 0.8547 - val_acc: 0.1235\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s - loss: 0.3154 - acc: 1.0000 - val_loss: 0.8518 - val_acc: 0.1235\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s - loss: 0.3076 - acc: 1.0000 - val_loss: 0.8482 - val_acc: 0.1358\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s - loss: 0.3000 - acc: 1.0000 - val_loss: 0.8430 - val_acc: 0.1358\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s - loss: 0.2929 - acc: 1.0000 - val_loss: 0.8358 - val_acc: 0.1358\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s - loss: 0.2860 - acc: 1.0000 - val_loss: 0.8287 - val_acc: 0.1358\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s - loss: 0.2800 - acc: 1.0000 - val_loss: 0.8222 - val_acc: 0.1852\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s - loss: 0.2746 - acc: 1.0000 - val_loss: 0.8165 - val_acc: 0.1852\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s - loss: 0.2689 - acc: 1.0000 - val_loss: 0.8117 - val_acc: 0.2099\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s - loss: 0.2638 - acc: 1.0000 - val_loss: 0.8080 - val_acc: 0.2099\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s - loss: 0.2592 - acc: 1.0000 - val_loss: 0.8046 - val_acc: 0.2593\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s - loss: 0.2548 - acc: 1.0000 - val_loss: 0.8007 - val_acc: 0.3210\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s - loss: 0.2511 - acc: 1.0000 - val_loss: 0.7969 - val_acc: 0.3333\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s - loss: 0.2475 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s - loss: 0.2438 - acc: 1.0000 - val_loss: 0.7887 - val_acc: 0.3827\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s - loss: 0.2401 - acc: 1.0000 - val_loss: 0.7840 - val_acc: 0.3827\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s - loss: 0.2365 - acc: 1.0000 - val_loss: 0.7792 - val_acc: 0.3827\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s - loss: 0.2330 - acc: 1.0000 - val_loss: 0.7740 - val_acc: 0.4198\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s - loss: 0.2296 - acc: 1.0000 - val_loss: 0.7683 - val_acc: 0.4691\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s - loss: 0.2261 - acc: 1.0000 - val_loss: 0.7620 - val_acc: 0.6296\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s - loss: 0.2227 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.7160\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s - loss: 0.2195 - acc: 1.0000 - val_loss: 0.7479 - val_acc: 0.7531\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s - loss: 0.2165 - acc: 1.0000 - val_loss: 0.7408 - val_acc: 0.7901\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s - loss: 0.2133 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.8395\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s - loss: 0.2102 - acc: 1.0000 - val_loss: 0.7262 - val_acc: 0.8642\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s - loss: 0.2071 - acc: 1.0000 - val_loss: 0.7188 - val_acc: 0.8889\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s - loss: 0.2041 - acc: 1.0000 - val_loss: 0.7120 - val_acc: 0.9136\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s - loss: 0.2012 - acc: 1.0000 - val_loss: 0.7055 - val_acc: 0.9136\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s - loss: 0.1986 - acc: 1.0000 - val_loss: 0.6994 - val_acc: 0.9383\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s - loss: 0.1961 - acc: 1.0000 - val_loss: 0.6935 - val_acc: 0.9259\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s - loss: 0.1935 - acc: 1.0000 - val_loss: 0.6881 - val_acc: 0.9259\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s - loss: 0.1909 - acc: 1.0000 - val_loss: 0.6827 - val_acc: 0.9259\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s - loss: 0.1884 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.9259\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s - loss: 0.1858 - acc: 1.0000 - val_loss: 0.6712 - val_acc: 0.9259\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s - loss: 0.1835 - acc: 1.0000 - val_loss: 0.6657 - val_acc: 0.9383\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s - loss: 0.1813 - acc: 1.0000 - val_loss: 0.6605 - val_acc: 0.9383\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s - loss: 0.1790 - acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.9383\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s - loss: 0.1768 - acc: 1.0000 - val_loss: 0.6505 - val_acc: 0.9506\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s - loss: 0.1746 - acc: 1.0000 - val_loss: 0.6458 - val_acc: 0.9506\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s - loss: 0.1726 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.9506\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s - loss: 0.1705 - acc: 1.0000 - val_loss: 0.6375 - val_acc: 0.9506\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s - loss: 0.1684 - acc: 1.0000 - val_loss: 0.6335 - val_acc: 0.9506\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s - loss: 0.1665 - acc: 1.0000 - val_loss: 0.6294 - val_acc: 0.9506\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s - loss: 0.1645 - acc: 1.0000 - val_loss: 0.6252 - val_acc: 0.9506\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s - loss: 0.1626 - acc: 1.0000 - val_loss: 0.6217 - val_acc: 0.9506\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s - loss: 0.1608 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.9630\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s - loss: 0.1589 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9630\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s - loss: 0.1570 - acc: 1.0000 - val_loss: 0.6131 - val_acc: 0.9630\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s - loss: 0.1553 - acc: 1.0000 - val_loss: 0.6103 - val_acc: 0.9630\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s - loss: 0.1537 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.9630\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s - loss: 0.1520 - acc: 1.0000 - val_loss: 0.6029 - val_acc: 0.9630\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s - loss: 0.1503 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.9630\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s - loss: 0.1486 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.9630\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s - loss: 0.1471 - acc: 1.0000 - val_loss: 0.5895 - val_acc: 0.9630\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s - loss: 0.1455 - acc: 1.0000 - val_loss: 0.5859 - val_acc: 0.9630\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s - loss: 0.1439 - acc: 1.0000 - val_loss: 0.5823 - val_acc: 0.9630\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s - loss: 0.1424 - acc: 1.0000 - val_loss: 0.5790 - val_acc: 0.9630\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s - loss: 0.1409 - acc: 1.0000 - val_loss: 0.5758 - val_acc: 0.9630\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s - loss: 0.1394 - acc: 1.0000 - val_loss: 0.5721 - val_acc: 0.9630\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s - loss: 0.1380 - acc: 1.0000 - val_loss: 0.5682 - val_acc: 0.9630\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s - loss: 0.1366 - acc: 1.0000 - val_loss: 0.5646 - val_acc: 0.9630\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s - loss: 0.1352 - acc: 1.0000 - val_loss: 0.5613 - val_acc: 0.9630\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s - loss: 0.1338 - acc: 1.0000 - val_loss: 0.5580 - val_acc: 0.9630\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s - loss: 0.1324 - acc: 1.0000 - val_loss: 0.5548 - val_acc: 0.9630\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s - loss: 0.1311 - acc: 1.0000 - val_loss: 0.5515 - val_acc: 0.9630\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s - loss: 0.1298 - acc: 1.0000 - val_loss: 0.5482 - val_acc: 0.9630\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s - loss: 0.1286 - acc: 1.0000 - val_loss: 0.5451 - val_acc: 0.9630\n",
      "Epoch 00076: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1093df60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import concatenate, Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model, Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import math\n",
    "\n",
    "\n",
    "# define parameters\n",
    "input_tensor_shape = (118,)\n",
    "epochs = 500\n",
    "\n",
    "#####################################################################################################\n",
    "######################################          Model          ######################################\n",
    "#####################################################################################################\n",
    "\n",
    "# Define Input\n",
    "inputs = Input(shape=input_tensor_shape)\n",
    "\n",
    "# FullBN (3) - (64, 32, 16)\n",
    "x = Dense(256, init = 'glorot_normal')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dense(64)(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dense(16)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "output = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "# compile model, summarize layers & plot graph\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "\n",
    "# define callbacks\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1, write_graph=True, write_grads=True, write_images=False)\n",
    "\n",
    "model.fit(X, Y, epochs = epochs, validation_split = 0.8, class_weight = {1:3.625, 0:1.0}, callbacks = [early], verbose = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv2D (6) - aux input at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Input, Conv2D, MaxPooling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import math\n",
    "\n",
    "# define parameters\n",
    "# define parameters\n",
    "img_width, img_height = 6, 6\n",
    "input_shape = (1, img_width, img_height)\n",
    "epochs = 500\n",
    "\n",
    "#####################################################################################################\n",
    "######################################          Model          ######################################\n",
    "#####################################################################################################\n",
    "\n",
    "inputs = Input(shape = (784, 60, 20))\n",
    "\n",
    "x = Conv2D(32, (3,3), input_shape = input_shape)(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(64, (3,3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(128, (3,3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(256, (3,3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "#merged = concatenate([meta_input, flat1])\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "# compile model, summarize layers & plot graph\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "\n",
    "# define callbacks\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_grads=True, write_images=False)\n",
    "\n",
    "model.fit([X1, X2], Y, epochs = epochs, validation_split = 0.8, class_weight = , callbacks = [tbCallBack, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception (6) - aux input at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Input, Conv2D, MaxPooling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import math\n",
    "\n",
    "# define parameters\n",
    "# define parameters\n",
    "img_width, img_height = 6, 6\n",
    "input_shape = (1, img_width, img_height)\n",
    "epochs = 500\n",
    "\n",
    "#####################################################################################################\n",
    "######################################          Model          ######################################\n",
    "#####################################################################################################\n",
    "\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "# combine towers, flatten and concat\n",
    "combined = concatenate([tower_1, tower_2, tower_3], axis=1)\n",
    "flat = Flatten()(combined)\n",
    "merged = concatenate([meta_data, flat])\n",
    "\n",
    "# last FCN\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(152, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "# compile model, summarize layers & plot graph\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "\n",
    "# define callbacks\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_grads=True, write_images=False)\n",
    "\n",
    "model.fit([X1, X2], Y, epochs = epochs, validation_split = 0.8, class_weight = , callbacks = [tbCallBack, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# merging\\ndf3 = pd.merge(df, df2, left_on = 'Patient ID', right_on = 'patient_id')\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# reading in data files\n",
    "df = pd.read_csv('Glaucoma metadata V1.csv')\n",
    "df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "df2 = pd.read_csv('patients_data_from_images.csv')\n",
    "\n",
    "# converting datetimes\n",
    "df['Date'] =  pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "df2['date_1'] =  pd.to_datetime(df2['date_1'], format='%Y%m%d')\n",
    "\n",
    "# processing meta data\n",
    "df.sort_values(['Patient ID', 'Date'], inplace = True)\n",
    "df = df[df['Right or Left'] == 0]\n",
    "df.drop_duplicates(['Patient ID', 'Date'], axis = 1, keep = 'first', inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df.to_csv('temp.csv', index = False)\n",
    "# processesed outside in excel to only keep first 2 record for each patient -- reimported\n",
    "df = pd.read_csv('temp2.csv', encoding='cp1252')\n",
    "df01 = df[df['Occurrence'] == 1]\n",
    "df02 = df[df['Occurrence'] == 2]\n",
    "df03 = df02[['Patient ID', 'VFI', 'MD', 'PSD', 'FL', 'FP', 'FN', 'GHT', 'BCVA', 'CDR','IOP']]\n",
    "df = pd.merge(df01, df03, on = 'Patient ID')\n",
    "df.to_csv('temp3.csv')\n",
    "\n",
    "\n",
    "# import and merge\n",
    "df = pd.read_csv('temp3.csv')\n",
    "df3 = pd.merge(df, df2, left_on = 'Patient ID', right_on = 'patient_id')\n",
    "df3.drop(['Patient ID', 'date_1', 'Duration', 'MD gradient'] , axis = 1, inplace = True)\n",
    "df3['MD Drop Fast'].replace({'True': 1, 'False': 0}, inplace = True)\n",
    "df3 = df3.applymap(lambda x: 1 if x == True else x)\n",
    "df3 = df3.applymap(lambda x: 0 if x == False else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#need to define label \n",
    "\n",
    "# Input Layer\n",
    "input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "# 1st Dense Layer\n",
    "x = tf.layers.dense(input_layer, 256, kernel_initializer = tf.glorot_normal_initializer())\n",
    "x = tf.layers.batch_normalization(x)\n",
    "x = tf.nn.relu(x, 'relu')\n",
    "\n",
    "# 2nd Dense Layer\n",
    "x = tf.layers.dense(input_layer, 128)\n",
    "x = tf.layers.batch_normalization(x)\n",
    "x = tf.nn.relu(x, 'relu')\n",
    "\n",
    "# 3rd Dense Layer\n",
    "x = tf.layers.dense(input_layer, 64)\n",
    "x = tf.layers.batch_normalization(x)\n",
    "x = tf.nn.relu(x, 'relu')\n",
    "\n",
    "# 4th Dense Layer\n",
    "x = tf.layers.dense(input_layer, 32)\n",
    "x = tf.layers.batch_normalization(x)\n",
    "x = tf.nn.relu(x, 'relu')\n",
    "\n",
    "# 5th Dense Layer\n",
    "x = tf.layers.dense(input_layer, units=16)\n",
    "x = tf.layers.batch_normalization(x)\n",
    "x = tf.nn.relu(x, 'relu')\n",
    "\n",
    "# dropout layer\n",
    "x = tf.layers.dropout(x, rate = 0.2)\n",
    "\n",
    "# logits layer\n",
    "logits = tf.layers.dense(x, 2)\n",
    "\n",
    "predictions = {\n",
    "  # Generate predictions (for PREDICT and EVAL mode)\n",
    "  \"classes\": tf.argmax(logits, axis=1),\n",
    "  # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "  # `logging_hook`.\n",
    "  \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "}\n",
    "\n",
    "# Calculate Loss (for both TRAIN and EVAL modes)\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "# Configure the Training Op (for TRAIN mode)\n",
    "if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(\n",
    "    loss=loss,\n",
    "    global_step=tf.train.get_global_step())\n",
    "return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "# Add evaluation metrics (for EVAL mode)\n",
    "eval_metric_ops = {\n",
    "  \"accuracy\": tf.metrics.accuracy(\n",
    "      labels=labels, predictions=predictions[\"classes\"])}\n",
    "return tf.estimator.EstimatorSpec(\n",
    "  mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2],\n",
       "       [2, 2, 2],\n",
       "       [2, 2, 2]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray.flatten(X2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 3 4 5 3 1 2 5 9 2 8]\n",
      "[1 2 5 4 5 3 1 2 5 9 2 8]\n",
      "[9 2 8 4 5 3 1 2 5 9 2 8]\n"
     ]
    }
   ],
   "source": [
    "for index, row in X1.iterrows():\n",
    "    print(np.concatenate((row.values,np.ndarray.flatten(X2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_list = list()\n",
    "\n",
    "for i in range(len(X1)):\n",
    "    arr = np.concatenate((X1[i].values,np.ndarray.flatten(X2[i])))\n",
    "    arr_list.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64),\n",
       " array([1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64),\n",
       " array([1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
